---
aliases: ["Learning Transferable Visual Models From Natural Language Supervision", "Learning Transferable Visual Models From Natural Language Supervision, 2021", "CLIP"]
---
# Learning Transferable Visual Models From Natural Language Supervision

- **Journal**: arxiv:2103.00020 [cs]
- **Author**: Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever
- **Year**: 2021
- **URL**: http://arxiv.org/abs/2103.00020
- [**Zotero**](zotero://select/items/@2021LearningTransferableVisualRadford)
- [**ReadPaper**](https://readpaper.com/pdf-annotate/note?pdfId=4557522938392223745&noteId=1551974810127710464)
- [bilibili](https://www.bilibili.com/video/BV1SL4y1s7LQ/)

## 论文试图解决的问题

%% 是否是新的问题。现状、难点。motivation %%

利用自然语言的监督信号学习一个视觉感知模型（对比学习）
> learning perception from supervision contained in natural language
- NLP从n-gram等复杂模型演变成Transformer等自监督的学习范式，从而能更好的利用丰富的语料资源，为多模态铺平了道路

## 论文的总体贡献

## 论文提供的关键元素、关键设计

### 总体流程

## 实验

%% 实现细节、设置。数据集。评估。消融实验 %%

如果完全OOD（out of distribution），那即使是简单的任务也做不好，例如手写数字识别

## 后续工作

%% 有什么疑问。如何继续深入。如何吸取到你的工作中 %%

## 相关研究

%% 如何归类。值得关注的研究员 %%
