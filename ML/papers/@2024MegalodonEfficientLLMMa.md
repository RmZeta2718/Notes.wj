---
aliases:
  - "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length"
  - "Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length, 2024"
---
# Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length

- **Journal**: arxiv:2404.08801
- **Author**: Xuezhe Ma, Xiaomeng Yang, Wenhan Xiong, Beidi Chen, Lili Yu, Hao Zhang, Jonathan May, Luke Zettlemoyer, Omer Levy, Chunting Zhou
- **Year**: 2024
- **URL**: http://arxiv.org/abs/2404.08801
- [**Zotero**](zotero://select/items/@2024MegalodonEfficientLLMMa)
- [**TODO ReadPaper**](https://readpaper.com/...)

## 论文试图解决的问题

%% 是否是新的问题。现状、难点。motivation %%

## 论文的总体贡献

## 论文提供的关键元素、关键设计

### 总体流程

## 实验

%% 实现细节、设置。数据集。评估。消融实验 %%

## 相关研究

%% 如何归类。值得关注的研究员 %%
