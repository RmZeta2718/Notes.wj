---
aliases:
  - "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time"
  - "Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time, 2023"
---
# Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time

- **Journal**: arxiv:2305.17118 #NeurIPS/23
- **Author**: Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie, Zhaozhuo Xu, Anastasios Kyrillidis, Anshumali Shrivastava
- **Year**: 2023
- **URL**: http://arxiv.org/abs/2305.17118
- [**Zotero**](zotero://select/items/@2023ScissorhandsExploitingPersistenceLiu)
- [**ReadPaper**](https://readpaper.com/pdf-annotate/note?pdfId=4794480684974473217)

## 论文试图解决的问题

%% 是否是新的问题。现状、难点。motivation %%

- LLM推理时的显存占用问题
- kv-cache驱逐策略
## 论文的总体贡献

## 论文提供的关键元素、关键设计

### 总体流程

## 实验

%% 实现细节、设置。数据集。评估。消融实验 %%

## 相关研究

%% 如何归类。值得关注的研究员 %%
