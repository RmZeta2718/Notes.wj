
- [[@2025LoLCATsLowRankLinearizingZhang|LoLCATs: On Low-Rank Linearizing of Large Language Models, 2025]]
    - [LoLCATs Blog Part 2: How to Linearize LLMs for Me and You · Hazy Research](https://hazyresearch.stanford.edu/blog/2024-10-14-lolcats-p2)
    - 前置工作：[[@2024HedgehogPorcupineExpressiveZhang|The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry, 2024]]

Mamba:
- [[@2025MambaLlamaDistillingWang|The Mamba in the Llama: Distilling and Accelerating Hybrid Models, 2025]]
