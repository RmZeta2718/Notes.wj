综述：
- [[@2021PromptingBetterWays|Prompting: Better Ways of Using Language Models for NLP Tasks, 2021]]

soft prompt:
- [[@2021PrefixTuningOptimizingContinuousLi|Prefix-Tuning: Optimizing Continuous Prompts for Generation, 2021]]
- [[@2021PowerScaleParameterEfficientLester|The Power of Scale for Parameter-Efficient Prompt Tuning, 2021]]
- [[@2022PTuningV2PromptLiu|P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks, 2022]]
- [[@2021FactualProbingMASKZhong|Factual Probing Is [MASK]: Learning vs. Learning to Recall, 2021]]

应用于持续学习：
- [[@2022OvercomingCatastrophicForgettingVu|Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation, 2022]]
