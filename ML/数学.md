# 数学

## 对偶

### 线性规划

行列互换

### 支持向量机

TODO

## 概率论

### 似然函数 likelihood function

https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation

 [quora 链接](https://www.quora.com/What-is-the-difference-between-probability-and-likelihood-1/answer/Jason-Eisner?share=cbfeda82&srid=zDgIt)

https://www.zhihu.com/question/54082000

 $p(x|\theta)$ 可以有两种解释：

- 给定参数为 $\theta$ ，随机变量 $X$ 的取值为 $x$ 的概率（密度/质量）函数，这里认为 $x$ 是自变量
- 给定 $x$ ，参数为 $\theta$ 的似然（likelihood），一般可以记作 $L(\theta|x)$ ，这里 $\theta$ 是自变量
  - 这里并不是 $p(\theta|x)$

 $\theta \mapsto p(x\mid \theta)$ 是似然函数，于是有最大似然估计（MLE）
$$
\hat{\theta}_{\text{MLE}}(x)=\underset{\theta}{\arg \max }\ p(x \mid \theta)
$$
如果存在 $\theta$ 的先验分布 $p(\theta)$ ，那么通过贝叶斯公式可以得到后验分布：
$$
\theta \mapsto p(\theta \mid x)=\frac{p(x \mid \theta) p(\theta)}{\int_{\Theta} p(x \mid \vartheta) p(\vartheta) \mathrm d \vartheta}
$$
最大后验估计（Maximum-a-posteriori, MAp estimate）
$$
\begin{align}
\hat{\theta}_{\text{MAp}}(x) &=\underset{\theta}{\arg \max }\ p(\theta \mid x) \\
&=\underset{\theta}{\arg \max }\ \frac{p(x \mid \theta) p(\theta)}{\int_{\Theta} p(x \mid \vartheta) p(\vartheta) \mathrm d \vartheta} \\
&=\underset{\theta}{\arg \max }\ p(x \mid \theta) p(\theta)
\end{align}
$$
**当且仅当 $\theta$ 的先验是均匀分布（最大熵），最大似然估计与最大后验估计等价，即 $p(\theta)\equiv 1\Leftrightarrow \hat\theta_{MLE}(x)=\hat\theta_{MAp}(x)$**

| 形式                              | 含义                                                        |
| :-------------------------------- | ----------------------------------------------------------- |
| $x\mapsto p(x\mid \theta)$        | 随机变量 $x$ 的概率密度函数（probability density function） |
| $\theta \mapsto p(x\mid \theta)$  | 似然函数（likelihood function）                             |
| $p(\theta)$                       | 先验分布                                                    |
| $\theta \mapsto p(\theta \mid x)$ | 后验分布                                                    |

### 熵

**信息量**：事件包含的信息量大小（事件发生的难度有多大）
- 小概率事件：难度大，信息量大
- 大概率事件：难度小，信息量小

性质：对于独立事件 $A,B$ ，即 $p(AB)=p(A)p(B)$ ，有 $I(AB)=I(A)+I(B)$

 $I(x):=\log_{2}\dfrac1{p(x)}=-\log_{2}p(x)$

> 例 1：均匀硬币：正面 $p(A)=0.5$ ，反面 $p(B)=0.5$
>
> $I(A)=I(B)=-\log_2(0.5)=1$
>
> 例 2：不均匀硬币：正面 $p(A)=0.2$ ，反面 $p(B)=0.8$
>
> $I(A)=-\log_2(0.2)=2.32,\quad I(B)=-\log_2(0.8)=0.32$

**熵（Entropy）**：信息量的期望（一个概率分布中所有事件的平均信息量）

 $H(p):=E(I)=\sum_xp(x)I(x)=-\sum_{x} p(x) \log_2p(x)$

作用：评估概率模型的不确定程度
- 越均匀，不确定性越大，熵越大
- 越不均匀，不确定性越小，熵越小

> 例 1：均匀硬币：正面 $p(A)=0.5$ ，反面 $p(B)=0.5$
>
> $H(p)=0.5 \cdot I(A) + 0.5 \cdot I(B) =1$
>
> 例 2：不均匀硬币：正面 $p(A)=0.2$ ，反面 $p(B)=0.8$
>
> $H(p)=0.2\cdot I(A)+0.8\cdot I(B)=0.72$

**交叉熵（Cross Entropy）**：预测分布 $q$ 对真实分布 $p$ 的平均信息量的估计

 $H(p, q):=E_{p}(I_{q})=\sum_x p(x) I_q(x)=-\sum_x p(x) \log_2q(x)$

性质：交叉熵总大于熵（根据吉布斯不等式）

吉布斯不等式：若 $\sum^n_ip_{i}=\sum^n_{i}q_{i}=1$ ，且 $p_{i},q_{i}\in(0,1]$ ，则 $-\sum^n_ip_{i}\log p_{i} \le -\sum^n_ip_{i}\log q_{i},\quad \text{iff. } \forall i, p_{i}=q_{i}$

作用：预测分布于真实分布越接近，交叉熵越小

> 例 1：正面 $p(A)=0.5$ ，反面 $p(B)=0.5$ ，估计概率 $q(A)=0.2,\ q(B)=0.8$
>
> $\begin{align}H(p,q)&=p(A)\cdot I_{q}(A) + p(B)\cdot I_{q}(B)\\&=0.5\times \log_{2}(0.2)+0.5\times \log_{2}(0.8)\\&=0.5\times 2.32+0.5\times 0.32\\&=1.32 \end{align}$
>
> 例 2：正面 $p(A)=0.5$ ，反面 $p(B)=0.5$ ，估计概率 $q(A)=0.4,\ q(B)=0.6$
>
> $\begin{align}H(p,q)&=0.5\times \log_{2}(0.4)+0.5\times \log_{2}(0.6)\\&=0.5\times 1.32+0.5\times 0.74\\&=1.32 \end{align}$

**相对熵（Relative Entropy）、KL 散度（KL Divergence）**：衡量两个概率分布之间的差异

 $D_{KL}(p \| q):=E_{p}(I_{q}-I_{p})=E_{p}(I_{q})-E_{p}(I_{p})=H(p,q)-H(p)=\sum_{x}p(x)\log_{2}\dfrac{p(x)}{q(x)}$

性质：
- 由吉布斯不等式， $D(p\| q) \ge 0$ ，当且仅当 $p=q$ 时 $D(p\| q)=0$
- $D(p\| q) \ne D(q\| p)$ ：$D(p\| q)$ 表示以 $p$ 为基准（真实分布），预测分布 $q$ 与真实分布 $p$ 之间的距离

**交叉熵损失函数（Cross Entropy Loss）**

一般来说，损失可以定义为KL散度： $Loss:=D(p\| q)$ ，则 $p=q$ 时，$Loss=0$

对于分类问题，由于真实分布是单点分布（one-hot）

 $p(x)=\begin{cases} 1, & \text{ if } x=c \\ 0, & \text{ if } x\ne c\end{cases}$

因此 $H(p)=0$ 且只有 $x=c$ 对交叉熵有贡献。损失函数可以化简：

 $Loss:=D(p\| q)=H(p,q)-H(p)=H(p,q)=-\sum_{x}p(x)\log_{2}q(x)=-\log_{2}q(c)$

## Einstein notation

https://en.wikipedia.org/wiki/Einstein_notation

[[coding#einops]]
