# 采坑记录

记录格式：

### 标题可以是问题类型或出错的模块
> 22/03/26（记录时间）

```
报错信息
```

排查：可能需要的排查流程

原因：分析问题原因

解决方案：

- 写明解决的步骤 1
- 步骤 2
- 。。。

参考资料：

### VS Code file watcher is running out of handles
> 23/03/15

 [Visual Studio Code is unable to watch for file changes in this large workspace](https://code.visualstudio.com/docs/setup/linux#_visual-studio-code-is-unable-to-watch-for-file-changes-in-this-large-workspace-error-enospc)

排查：
- 大概是因为我把 torch 的 index 深度增加了（`python.analysis.packageIndexDepths`），导致 vscode 没法 index 这么多文件。
- 调小之后问题仍然存在。
- 搜索到了 [inotify-consumers](https://github.com/fatso83/dotfiles/blob/master/utils/scripts/inotify-consumers) 脚本，可以查看哪个进程在占用handle。（根据脚本注释，有一个C++编译的版本，速度更快，但是我认为没有必要，shell脚本可以方便地嵌入dotfiles）
- 发现 vscode server 在占用。于是 kill server（`Remote-SSH: Kill Current VS Code Server`），再重新连接，恢复正常。

### 显存不足
> 22/03/26

```
RuntimeError: CUDA out of memory.Tried to allocate 20.00 MiB
```

排查： `nvidia-smi` 查看显卡状况

解决方案：

- 将 batchsize 改小一些
- 根据显卡状况，更换 GPU id

### nn.DataParallel BUG
> 22/03/26

```
StopIteration: Caught StopIteration in replica 0 on device 0.
```

原因：pytorch 单机多卡用 nn.DataParallel 的时候无法 forward，会报错。pytorch1.5 的 bug

解决方案：

- 不用 nn.DataParallel
- 或者降级到 pytorch==1.4

参考：https://blog.csdn.net/sunflower_sara/article/details/109674853

# 一些灵异事件

> 影响不大但是很奇怪的事情

### torch.Tensor.sum() undocumented keyword `keepdims`
> 23/01/31

 [pytorch 文档](https://pytorch.org/docs/stable/generated/torch.Tensor.sum.html#torch.Tensor.sum) 中的 keyword argument 是 `keepdim` 但是 `keepdims` 竟然也可以（可能是历史原因？）

不过 [numpy 文档](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) 里是 `keepdims` ，也有可能是把未知 `kwargs` 向 numpy 透传了
