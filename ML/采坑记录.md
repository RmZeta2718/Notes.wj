# 采坑记录

记录格式：

### 标题可以是问题类型或出错的模块

> 22/03/26（记录时间）

```
报错信息
```

排查：可能需要的排查流程

原因：分析问题原因

解决方案：

- 写明解决的步骤 1
- 步骤 2
- 。。。

参考资料：

### python 全局变量 import

> 24/11/09

https://discuss.python.org/t/global-variables-shared-across-modules/16833/5

全局变量是 module level 的，在另一个文件里 import 全局变量只能拿到初始值，不能在 module 间保持同步。

### accelerate 自动将模型输出转为 fp32

> 24/10/30

https://github.com/huggingface/accelerate/blob/ba7ab93f5e688466ea56908ea3b056fae2f9a023/src/accelerate/accelerator.py#L1402

发现输出类型不对，调试时观察 call stack 发现了 wrapper

### torch.compile 导致 python @cache 失效

> 24/10/26

@cache 可能会被 compile 优化掉，因此需要在这个函数上关闭优化

```python
from functools import cache
from torch._dynamo import disable

@disable
@cache
def log_once(logger: Logger, msg: str):
    logger.warning(msg)

```

### yaml 重复 key 问题

[Duplicate keys are not handled properly · Issue #165 · yaml/pyyaml (github.com)](https://github.com/yaml/pyyaml/issues/165)

yaml 不允许重复的 key，即下面的配置是不允许的，必须合在一起写，而不是分开写。

```yaml
foo:
    a: 1

foo:
    b: 2
```

pyyaml 在这种情况下没有报错，而是取了

### Out of memory when I use torch.cuda.empty_cache

> 24/02/05

[Out of memory when I use torch.cuda.empty_cache - PyTorch Forums](https://discuss.pytorch.org/t/out-of-memory-when-i-use-torch-cuda-empty-cache/57898)

`torch.cuda.empty_cache()` 会在 GPU0 上申请内存，需要用 `with torch.cuda.device("cuda:1"):` 包裹才能避免此问题。

### RuntimeError: CUDA error: device-side assert triggered

> 23/11/09

https://stackoverflow.com/a/51701698/17347885

- 先按照提示 `export CUDA_LAUNCH_BLOCKING=1`，这样就能定位到准确的报错位置（否则，根据提示，stack trace 可能是错误的）（此时报错没有变化，仅 stack trace 变化）
- 然后根据正确的 stack trace，将报错行（所有相关 `Tensor` `Module`）移到 CPU（`.to('cpu')`），就能看到更加详细的报错，而不是 `device-side assert`

### libstdc++.so.6: version 'GLIBCXX_3.4.26' not found

> 23/03/19

scipy 报错，重装不起作用，降版本不起作用

执行改命令，发现对应版本不存在

```bash
strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX
```

[github 上的解决方案可行](https://github.com/lhelontra/tensorflow-on-arm/issues/13#issuecomment-489296444) （升级），直接升级不行，需要先添加 ppa（可能是 ubuntu18 版本太低了）

```bash
sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get install --only-upgrade libstdc++6
```

### CondaVerificationError

> 23/03/16

```
CondaVerificationError: The package for _openmp_mutex located at /home/jiewang/.conda/pkgs/_openmp_mutex-5.1-1_gnu appears to be corrupted. The path 'lib/libgomp.so.1' specified in the package manifest cannot be found.
```

[jupyter - Conda Verification Failed - Data Science Stack Exchange](https://datascience.stackexchange.com/questions/41732/conda-verification-failed)

remove 再 install 之后恢复正常

### 显存不足

> 22/03/26

```
RuntimeError: CUDA out of memory.Tried to allocate 20.00 MiB
```

排查： `nvidia-smi` 查看显卡状况

解决方案：

- 将 batchsize 改小一些
- 根据显卡状况，更换 GPU id

### nn.DataParallel BUG

> 22/03/26

```
StopIteration: Caught StopIteration in replica 0 on device 0.
```

原因：pytorch 单机多卡用 nn.DataParallel 的时候无法 forward，会报错。pytorch1.5 的 bug

解决方案：

- 不用 nn.DataParallel
- 或者降级到 `pytorch==1.4`

参考： https://blog.csdn.net/sunflower_sara/article/details/109674853

# 一些灵异事件

> 影响不大但是很奇怪的事情

### torch.Tensor.sum() undocumented keyword `keepdims`

> 23/01/31

[pytorch 文档](https://pytorch.org/docs/stable/generated/torch.Tensor.sum.html#torch.Tensor.sum) 中的 keyword argument 是 `keepdim` 但是 `keepdims` 竟然也可以（可能是历史原因？）

不过 [numpy 文档](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) 里是 `keepdims` ，也有可能是把未知 `kwargs` 向 numpy 透传了
